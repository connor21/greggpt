# greggpt configuration
docs_dir: "docs"
vectorstore_path: "vectorstore"

# Model configuration
models:
  tinyllama:
    path: "models/tinyllama-1.1b-chat-v1.0.Q2_K.gguf"
    max_tokens: 512
    temperature: 0.7
    top_p: 0.9
  llama:
    path: "models/llama-2-7b-chat.Q4_K_M.gguf"
    max_tokens: 512
    temperature: 0.7
    top_p: 0.9
  mistral:
    path: "models/mistral-7b-instruct-v0.1.Q4_K_M.gguf"
    max_tokens: 1024
    temperature: 0.8
    top_p: 0.95
    
active_model: "mistral"  # Default model

# Chunking settings
chunk_size: 1000
chunk_overlap: 200

# Logging configuration
logging:
  level: "INFO"

# Hardware configuration
hardware:
  enable_gpu: true
  gpu_preferred: true
  fallback_to_cpu: true
